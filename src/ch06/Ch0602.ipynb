{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31501654e2bf4fe29042e125e32fccdc90463327bf0ec9fd2043d87fff9a6008"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 6.2 Convolutions for Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import mxnet as d2l\n",
    "from mxnet import autograd,np,npx\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[19., 25.],\n",
       "       [37., 43.]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# 6.2.1 The Cross-Correlation Operation\n",
    "def corr2d(X,K):\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h,w=K.shape\n",
    "    Y=np.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=d2l.reduce_sum(X[i:i+h,j:j+w]*K)\n",
    "    return Y\n",
    "\n",
    "X=np.arange(9).reshape((3,3))\n",
    "K=np.arange(4).reshape((2,2))\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2.2 Convolutional Layers\n",
    "class Conv2D(nn.Block):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight=self.params.get('weight',shape=kernel_size)\n",
    "        self.bias=self.params.get('bias',shape=(1,))\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight.data()+self.bais.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# 6.2.3 Object Edge Detection in Images\n",
    "X=np.ones((6,8))\n",
    "X[:,2:6]=0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "K=np.array([[1.0,-1.0]])\n",
    "Y=corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# K 是 Kernel，只能用于检测垂直边界，检测水平边界则图形消失\n",
    "corr2d(X.T,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch 2, loss 5.063\nbatch 4, loss 0.864\nbatch 6, loss 0.151\nbatch 8, loss 0.028\nbatch 10, loss 0.006\n"
     ]
    }
   ],
   "source": [
    "# 6.2.4 Learning a Kernel\n",
    "conv2d=nn.Conv2D(1,kernel_size=(1,2),use_bias=False)\n",
    "conv2d.initialize()\n",
    "\n",
    "# conv2d 需要四维的输入和输出数据(example, channel, height, width)\n",
    "# example = 每个批次中的数据个数，channel= 图形的通道数\n",
    "X=X.reshape(1,1,6,8)\n",
    "Y=Y.reshape(1,1,6,7)\n",
    "\n",
    "for i in range(10):\n",
    "    with autograd.record():\n",
    "        Y_hat=conv2d(X)\n",
    "        l=(Y_hat-Y)**2\n",
    "    l.backward()\n",
    "    # 更新卷积核的参数\n",
    "    conv2d.weight.data()[:]-=3e-2*conv2d.weight.grad()\n",
    "    if (i+1)%2==0:\n",
    "        print(f'batch {i+1}, loss {float(l.sum()):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2.5 Cross-Correlation and Convolution\n",
    "# 6.2.6 Feature Map and Receptive Field"
   ]
  }
 ]
}